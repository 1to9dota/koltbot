import { mkdtempSync } from "node:fs";
import { join } from "node:path";
import { tmpdir } from "node:os";
import { streamSimple } from "@mariozechner/pi-ai";
import { discoverAuthStorage, discoverModels } from "@mariozechner/pi-coding-agent";
import { ensureMoltbotModelsJson } from "./dist/agents/models-config.js";

async function testOllamaIntegration() {
  const agentDir = mkdtempSync(join(tmpdir(), "koltbot-test-"));
  console.log("ğŸ§ª Testing Ollama integration (with patch)...\n");

  try {
    // 1. ç”Ÿæˆ models.json
    console.log("Step 1: Generating models.json...");
    await ensureMoltbotModelsJson({}, agentDir);
    console.log("âœ… models.json generated\n");

    // 2. è®¾ç½® authStorageï¼ˆä¸éœ€è¦çœŸå® API keyï¼‰
    console.log("Step 2: Setting up authStorage...");
    const authStorage = discoverAuthStorage(agentDir);
    authStorage.setRuntimeApiKey("ollama", "ollama");
    console.log("âœ… AuthStorage configured\n");

    // 3. å‘ç°æ¨¡å‹
    console.log("Step 3: Discovering models...");
    const modelRegistry = discoverModels(authStorage, agentDir);
    const allModels = modelRegistry.getAll();
    const ollamaModels = allModels.filter(m => m.provider === "ollama");

    if (ollamaModels.length === 0) {
      console.log("âŒ No Ollama models found");
      return;
    }

    console.log("âœ… Ollama models found:", ollamaModels.length);
    ollamaModels.forEach(m => {
      console.log(`   - ${m.provider}/${m.id}`);
    });
    console.log();

    // 4. å‘é€æµ‹è¯•è¯·æ±‚
    console.log("Step 4: Sending test request to Ollama...");
    const model = ollamaModels[0];
    console.log("   Using model:", model.provider + "/" + model.id);
    console.log("   Base URL:", model.baseUrl);
    console.log();

    const messages = [
      { role: "user", content: "ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚" }
    ];

    console.log("ğŸ’¬ Request:");
    console.log("   User: ä½ å¥½ï¼è¯·ç”¨ä¸€å¥è¯ä»‹ç»ä½ è‡ªå·±ã€‚\n");
    console.log("ğŸ’¬ Response:");
    process.stdout.write("   Assistant: ");

    let responseText = "";
    let chunkCount = 0;

    for await (const chunk of streamSimple(model, { messages })) {
      if (chunk.type === "text_delta") {
        process.stdout.write(chunk.delta);
        responseText += chunk.delta;
        chunkCount++;
      }
    }

    console.log("\n");
    console.log("âœ… SUCCESS: Ollama integration fully working!");
    console.log("   Response length:", responseText.length, "characters");
    console.log("   Chunks received:", chunkCount);

  } catch (error) {
    console.log("\nâŒ FAILED");
    console.error("Error:", error.message);
    if (error.stack) {
      console.error("\nStack trace:");
      console.error(error.stack);
    }
  }
}

testOllamaIntegration();
